### ESPA√ëOL (ES)

Express.js tiene la reputaci√≥n de ser "r√°pido, sin opini√≥n y minimalista", pero esa libertad es un arma de doble filo. Una configuraci√≥n por defecto de Express ("Hello World") puede manejar cientos de requests, pero se derrumbar√° bajo carga real si no entiendes c√≥mo funciona el **Single-Threaded Event Loop**.

En este an√°lisis, convertiremos una app Express fr√°gil en una bestia de rendimiento capaz de servir 10k RPS, abordando bloat de middleware, bloqueo del event loop y tuning de base de datos.

#### 1. El Enemigo #1: Bloqueo del Event Loop

![Event Loop Blocking](./images/expressjs-performance-tuning/clinic-doctor.png)

Node.js es as√≠ncrono, pero su hilo principal es s√≠ncrono. Si ejecutas `JSON.parse` en un archivo de 50MB o calculas un hash criptogr√°fico en el hilo principal, **nadie m√°s puede entrar**.

**Diagn√≥stico con Clinic.js**:
Antes de optimizar, mide. Usa `clinic doctor` para detectar picos en el Event Loop Delay.

```bash
npm install -g clinic
clinic doctor -- on -c 'autocannon -c 100 localhost:3000' node server.js
```

**Soluci√≥n: Offloading a Worker Threads**:
Para tareas intensivas en CPU (Image resizing, PDF generation), usa `piscina` o `worker_threads` nativos.

```typescript
// worker-pool.ts
import Piscina from "piscina";

export const imageResizePool = new Piscina({
  filename: path.resolve(__dirname, "image-worker.js"),
});

// controller.ts
app.post("/upload", async (req, res) => {
  // üö´ BLOCKING: const result = resizeSync(req.file);
  // ‚úÖ NON-BLOCKING: Delega al thread pool
  const result = await imageResizePool.run(req.file.buffer);
  res.send(result);
});
```

#### 2. Tuning de Conexiones a Base de Datos (Pool Sizing)

Un error com√∫n es pensar "m√°s conexiones = m√°s velocidad". Falso. PostgreSQL tiene un l√≠mite de concurrencia efectiva ligado a los n√∫cleos de CPU.
Si tu pool es de 100 y tu DB tiene 4 cores, est√°s perdiendo tiempo en _Context Switching_.

**F√≥rmula M√°gica (aprox)**: `(Core Count * 2) + Spindle Count`

En Node.js/Drizzle, configura tu pool para ser agresivo con el `idleTimeout` para liberar recursos r√°pido en arquitecturas Serverless/Lambda, pero estable en contenedores de larga duraci√≥n.

```typescript
// database.ts
import { Pool } from "pg";

export const pool = new Pool({
  host: process.env.DB_HOST,
  max: 20, // Mant√©n esto alineado con la capacidad real de tu DB
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
});
```

#### 3. Middleware Bloat y Compresi√≥n Inteligente

Cada `app.use()` a√±ade latencia. Parsear JSON globalmente (`app.use(json())`) desperdicia CPU en webhooks o subidas de binarios que no lo necesitan.

Adem√°s, usa **Brotli** sobre Gzip. Es m√°s lento de comprimir, pero despimprime mucho m√°s r√°pido y genera archivos m√°s peque√±os (crucial para m√≥viles).

```typescript
import compression from "compression";

// Aplica middleware SOLO donde sea necesario
app.use("/api", json());

app.use(
  compression({
    filter: (req, res) => {
      if (req.headers["x-no-compression"]) return false;
      return compression.filter(req, res);
    },
    level: 6, // Balance perfecto CPU/Tama√±o para Brotli
  }),
);
```

#### 4. Streaming de Big Data (JSON/CSV)

Nunca uses `res.json(bigArray)`. Esto carga 1GB de datos en RAM para enviar 100MB de JSON. El Garbage Collector se volver√° loco parando el mundo ("Stop-the-world GC").
Usa flujos (Streams) para entubar la base de datos directo a la red.

```typescript
// export-controller.ts
import { pipeline } from "node:stream/promises";

app.get("/export-users", async (req, res) => {
  res.setHeader("Content-Type", "application/json");

  // Cursor de Drizzle: Lee fila a fila, bajo memory footprint
  const usersCursor = await db.select().from(users).iterator();

  // Transform Stream personalizado
  const jsonStream = new Transform({
    writableObjectMode: true,
    transform(chunk, encoding, callback) {
      this.push(JSON.stringify(chunk) + "\n");
      callback();
    },
  });

  // Pipeline maneja backpressure autom√°ticamente
  await pipeline(usersCursor, jsonStream, res);
});
```

#### 5. Clustering vs PM2

Node es single-core. Si tienes una instancia EC2 con 8 vCPUs, est√°s desperdiciando 7.
En Kubernetes, se prefiere escalar Pods (R√©plicas). Pero en VMs o Bare Metal, usa **Cluster Module**.

**PM2** es el est√°ndar de la industria para gestionar esto sin c√≥digo, pero entender c√≥mo funciona (`fork`) es vital.

```bash
# Production Start
pm2 start dist/main.js -i max --name api-prod
```

PM2 balancea las conexiones entrantes (Round Robin) entre los processos hijos. Si uno muere, PM2 lo revive (Zero Downtime Reload).

Hacer que Express vuele no es magia negra; es entender el costo computacional de cada funci√≥n que a√±ades al stack, respetar el Event Loop y gestionar la memoria como un recurso finito.

---

### ENGLISH (EN)

Express.js has a reputation for being "fast, unopinionated, and minimalist," but that freedom is a double-edged sword. A default Express configuration ("Hello World") can handle hundreds of requests but will crumble under real load if you don't understand how the **Single-Threaded Event Loop** works.

In this analysis, we will turn a fragile Express app into a performance beast capable of serving 10k RPS, addressing middleware bloat, event loop blocking, and database tuning.

#### 1. Enemy #1: Event Loop Blocking

![Event Loop Blocking](./images/expressjs-performance-tuning/clinic-doctor.png)

Node.js is asynchronous, but its main thread is synchronous. If you execute `JSON.parse` on a 50MB file or calculate a cryptographic hash on the main thread, **nobody else can enter**.

**Diagnosis with Clinic.js**:
Before optimizing, measure. Use `clinic doctor` to detect spikes in Event Loop Delay.

```bash
npm install -g clinic
clinic doctor -- on -c 'autocannon -c 100 localhost:3000' node server.js
```

**Solution: Worker Threads Offloading**:
For CPU-intensive tasks (Image resizing, PDF generation), use `piscina` or native `worker_threads`.

```typescript
// worker-pool.ts
import Piscina from "piscina";

export const imageResizePool = new Piscina({
  filename: path.resolve(__dirname, "image-worker.js"),
});

// controller.ts
app.post("/upload", async (req, res) => {
  // üö´ BLOCKING: const result = resizeSync(req.file);
  // ‚úÖ NON-BLOCKING: Delegate to thread pool
  const result = await imageResizePool.run(req.file.buffer);
  res.send(result);
});
```

#### 2. Database Connection Tuning (Pool Sizing)

A common mistake is thinking "more connections = more speed". False. PostgreSQL has an effective concurrency limit tied to CPU cores.
If your pool is 100 and your DB has 4 cores, you are wasting time on _Context Switching_.

**Magic Formula (approx)**: `(Core Count * 2) + Spindle Count`

In Node.js/Drizzle, configure your pool to be aggressive with `idleTimeout` to free resources fast in Serverless/Lambda architectures, but stable in long-running containers.

```typescript
// database.ts
import { Pool } from "pg";

export const pool = new Pool({
  host: process.env.DB_HOST,
  max: 20, // Keep this aligned with your DB's actual capacity
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
});
```

#### 3. Middleware Bloat and Smart Compression

Every `app.use()` adds latency. Globally parsing JSON (`app.use(json())`) wastes CPU on webhooks or binary uploads that don't need it.

Also, use **Brotli** over Gzip. It's slower to compress but decompresses much faster and generates smaller files (critical for mobile).

```typescript
import compression from "compression";

// Apply middleware ONLY where needed
app.use("/api", json());

app.use(
  compression({
    filter: (req, res) => {
      if (req.headers["x-no-compression"]) return false;
      return compression.filter(req, res);
    },
    level: 6, // Perfect CPU/Size balance for Brotli
  }),
);
```

#### 4. Streaming Big Data (JSON/CSV)

Never use `res.json(bigArray)`. This loads 1GB of data into RAM to send 100MB of JSON. The Garbage Collector will go crazy stopping the world ("Stop-the-world GC").
Use Streams to pipe the database directly to the network.

```typescript
// export-controller.ts
import { pipeline } from "node:stream/promises";

app.get("/export-users", async (req, res) => {
  res.setHeader("Content-Type", "application/json");

  // Drizzle Cursor: Read row by row, low memory footprint
  const usersCursor = await db.select().from(users).iterator();

  // Custom Transform Stream
  const jsonStream = new Transform({
    writableObjectMode: true,
    transform(chunk, encoding, callback) {
      this.push(JSON.stringify(chunk) + "\n");
      callback();
    },
  });

  // Pipeline handles backpressure automatically
  await pipeline(usersCursor, jsonStream, res);
});
```

#### 5. Clustering vs PM2

Node is single-core. If you have an EC2 instance with 8 vCPUs, you are wasting 7.
In Kubernetes, scaling Pods (Replicas) is preferred. But on VMs or Bare Metal, use the **Cluster Module**.

**PM2** is the industry standard for managing this code-free, but understanding how it works (`fork`) is vital.

```bash
# Production Start
pm2 start dist/main.js -i max --name api-prod
```

PM2 balances incoming connections (Round Robin) among child processes. If one dies, PM2 revives it (Zero Downtime Reload).

Making Express fly isn't black magic; it's understanding the computational cost of every function you add to the stack, respecting the Event Loop, and managing memory as a finite resource.

---

### PORTUGU√äS (PT)

O Express.js tem a reputa√ß√£o de ser "r√°pido, sem opini√£o e minimalista", mas essa liberdade √© uma faca de dois gumes. Uma configura√ß√£o padr√£o do Express ("Hello World") pode lidar com centenas de requisi√ß√µes, mas desmoronar√° sob carga real se voc√™ n√£o entender como funciona o **Single-Threaded Event Loop**.

Nesta an√°lise, transformaremos um aplicativo Express fr√°gil em uma fera de desempenho capaz de servir 10k RPS, abordando incha√ßo (bloat) de middleware, bloqueio do event loop e ajuste fino de banco de dados.

#### 1. Inimigo #1: Bloqueio do Event Loop

![Event Loop Blocking](./images/expressjs-performance-tuning/clinic-doctor.png)

O Node.js √© ass√≠ncrono, mas seu thread principal √© s√≠ncrono. Se voc√™ executar `JSON.parse` em um arquivo de 50MB ou calcular um hash criptogr√°fico no thread principal, **ningu√©m mais poder√° entrar**.

**Diagn√≥stico com Clinic.js**:
Antes de otimizar, me√ßa. Use `clinic doctor` para detectar picos no atraso do Event Loop.

```bash
npm install -g clinic
clinic doctor -- on -c 'autocannon -c 100 localhost:3000' node server.js
```

**Solu√ß√£o: Offloading para Worker Threads**:
Para tarefas intensivas em CPU (redimensionamento de imagem, gera√ß√£o de PDF), use `piscina` ou `worker_threads` nativos.

```typescript
// worker-pool.ts
import Piscina from "piscina";

export const imageResizePool = new Piscina({
  filename: path.resolve(__dirname, "image-worker.js"),
});

// controller.ts
app.post("/upload", async (req, res) => {
  // üö´ BLOCKING: const result = resizeSync(req.file);
  // ‚úÖ NON-BLOCKING: Delegar para o pool de threads
  const result = await imageResizePool.run(req.file.buffer);
  res.send(result);
});
```

#### 2. Tuning de Conex√µes de Banco de Dados (Pool Sizing)

Um erro comum √© pensar "mais conex√µes = mais velocidade". Falso. O PostgreSQL tem um limite de concorr√™ncia efetiva ligado aos n√∫cleos da CPU.
Se o seu pool for 100 e seu BD tiver 4 n√∫cleos, voc√™ estar√° perdendo tempo em _Context Switching_.

**F√≥rmula M√°gica (aprox)**: `(Contagem de N√∫cleos * 2) + Contagem de Eixos`

No Node.js/Drizzle, configure seu pool para ser agressivo com o `idleTimeout` para liberar recursos rapidamente em arquiteturas Serverless/Lambda, mas est√°vel em cont√™ineres de longa dura√ß√£o.

```typescript
// database.ts
import { Pool } from "pg";

export const pool = new Pool({
  host: process.env.DB_HOST,
  max: 20, // Mantenha isso alinhado com a capacidade real do seu BD
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
});
```

#### 3. Middleware Bloat e Compress√£o Inteligente

Cada `app.use()` adiciona lat√™ncia. Analisar JSON globalmente (`app.use(json())`) desperdi√ßa CPU em webhooks ou uploads bin√°rios que n√£o precisam disso.

Al√©m disso, use **Brotli** sobre Gzip. √â mais lento para comprimir, mas descomprime muito mais r√°pido e gera arquivos menores (cr√≠tico para dispositivos m√≥veis).

```typescript
import compression from "compression";

// Aplique middleware APENAS onde necess√°rio
app.use("/api", json());

app.use(
  compression({
    filter: (req, res) => {
      if (req.headers["x-no-compression"]) return false;
      return compression.filter(req, res);
    },
    level: 6, // Equil√≠brio perfeito CPU/Tamanho para Brotli
  }),
);
```

#### 4. Streaming de Big Data (JSON/CSV)

Nunca use `res.json(bigArray)`. Isso carrega 1GB de dados na RAM para enviar 100MB de JSON. O Garbage Collector ficar√° louco parando o mundo ("Stop-the-world GC").
Use Streams para canalizar o banco de dados direto para a rede.

```typescript
// export-controller.ts
import { pipeline } from "node:stream/promises";

app.get("/export-users", async (req, res) => {
  res.setHeader("Content-Type", "application/json");

  // Drizzle Cursor: L√™ linha por linha, baixo consumo de mem√≥ria
  const usersCursor = await db.select().from(users).iterator();

  // Transform Stream personalizado
  const jsonStream = new Transform({
    writableObjectMode: true,
    transform(chunk, encoding, callback) {
      this.push(JSON.stringify(chunk) + "\n");
      callback();
    },
  });

  // Pipeline lida com backpressure automaticamente
  await pipeline(usersCursor, jsonStream, res);
});
```

#### 5. Clustering vs PM2

Node √© single-core. Se voc√™ tem uma inst√¢ncia EC2 com 8 vCPUs, est√° desperdi√ßando 7.
No Kubernetes, escalar Pods (R√©plicas) √© prefer√≠vel. Mas em VMs ou Bare Metal, use o **Cluster Module**.

**PM2** √© o padr√£o da ind√∫stria para gerenciar isso sem c√≥digo, mas entender como funciona (`fork`) √© vital.

```bash
# Production Start
pm2 start dist/main.js -i max --name api-prod
```

O PM2 balanceia as conex√µes recebidas (Round Robin) entre os processos filhos. Se um morrer, o PM2 o revive (Zero Downtime Reload).

Fazer o Express voar n√£o √© magia negra; √© entender o custo computacional de cada fun√ß√£o que voc√™ adiciona √† pilha, respeitar o Event Loop e gerenciar a mem√≥ria como um recurso finito.
